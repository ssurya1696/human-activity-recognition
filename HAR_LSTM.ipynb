{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 1.3312 - acc: 0.4323 - val_loss: 1.1683 - val_acc: 0.4846\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 1.0265 - acc: 0.5618 - val_loss: 0.9187 - val_acc: 0.5945\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.8139 - acc: 0.6488 - val_loss: 0.7853 - val_acc: 0.6193\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 55s 7ms/step - loss: 0.7096 - acc: 0.6689 - val_loss: 0.7408 - val_acc: 0.6159\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.6401 - acc: 0.6880 - val_loss: 0.7020 - val_acc: 0.6664\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.6230 - acc: 0.6979 - val_loss: 0.7287 - val_acc: 0.7017\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.5834 - acc: 0.7262 - val_loss: 0.6355 - val_acc: 0.7268\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.5487 - acc: 0.7481 - val_loss: 0.6564 - val_acc: 0.7306\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.4930 - acc: 0.7803 - val_loss: 0.6182 - val_acc: 0.7360\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.4556 - acc: 0.7900 - val_loss: 0.5948 - val_acc: 0.7112\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.4074 - acc: 0.8039 - val_loss: 0.5054 - val_acc: 0.7421\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.3793 - acc: 0.8252 - val_loss: 0.4603 - val_acc: 0.7808\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.3665 - acc: 0.8630 - val_loss: 0.5039 - val_acc: 0.8612\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.3789 - acc: 0.8876 - val_loss: 0.4645 - val_acc: 0.8480\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.3372 - acc: 0.9055 - val_loss: 0.4003 - val_acc: 0.8687\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.2673 - acc: 0.9210 - val_loss: 0.4191 - val_acc: 0.8473\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.2368 - acc: 0.9236 - val_loss: 0.3641 - val_acc: 0.8867\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.2131 - acc: 0.9323 - val_loss: 0.4253 - val_acc: 0.8833\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.2135 - acc: 0.9347 - val_loss: 0.3123 - val_acc: 0.8985\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1983 - acc: 0.9407 - val_loss: 0.4502 - val_acc: 0.8914\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2383 - acc: 0.9308 - val_loss: 0.3462 - val_acc: 0.8931\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1764 - acc: 0.9441 - val_loss: 0.4002 - val_acc: 0.8958\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1920 - acc: 0.9406 - val_loss: 0.5881 - val_acc: 0.8850\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2227 - acc: 0.9361 - val_loss: 0.3583 - val_acc: 0.8992\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1895 - acc: 0.9421 - val_loss: 0.4919 - val_acc: 0.8748\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1905 - acc: 0.9438 - val_loss: 0.3812 - val_acc: 0.8826\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1918 - acc: 0.9416 - val_loss: 0.4873 - val_acc: 0.8951\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1648 - acc: 0.9463 - val_loss: 0.3695 - val_acc: 0.8992\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1799 - acc: 0.9442 - val_loss: 0.4771 - val_acc: 0.8884\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1605 - acc: 0.9465 - val_loss: 0.4689 - val_acc: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c95e983b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         1        0                   0   \n",
      "SITTING                  0      419        51        0                   1   \n",
      "STANDING                 0      132       397        2                   0   \n",
      "WALKING                  0        0         0      466                  29   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 416   \n",
      "WALKING_UPSTAIRS         0        1         0       22                  14   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            26  \n",
      "SITTING                           20  \n",
      "STANDING                           1  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 434  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 589us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46892408261934193, 0.8965049202578894]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 64 hidden layer , 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 1.3249 - acc: 0.4149 - val_loss: 1.2714 - val_acc: 0.4177\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 1.1012 - acc: 0.4974 - val_loss: 1.2991 - val_acc: 0.4119\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 1.0031 - acc: 0.5642 - val_loss: 0.9688 - val_acc: 0.6118\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.9098 - acc: 0.5977 - val_loss: 1.0611 - val_acc: 0.5405\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.9908 - acc: 0.5503 - val_loss: 0.7473 - val_acc: 0.6552\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.7811 - acc: 0.6480 - val_loss: 0.8354 - val_acc: 0.6145\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.7068 - acc: 0.6763 - val_loss: 0.8029 - val_acc: 0.6573\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.6469 - acc: 0.7133 - val_loss: 0.6621 - val_acc: 0.7391\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.5707 - acc: 0.7682 - val_loss: 0.6820 - val_acc: 0.7516\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4987 - acc: 0.8194 - val_loss: 0.7530 - val_acc: 0.7930\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4104 - acc: 0.8645 - val_loss: 0.5833 - val_acc: 0.7757\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.3391 - acc: 0.8897 - val_loss: 0.4701 - val_acc: 0.8765\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2766 - acc: 0.9075 - val_loss: 0.4440 - val_acc: 0.8768\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2310 - acc: 0.9229 - val_loss: 0.4140 - val_acc: 0.8863\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2281 - acc: 0.9267 - val_loss: 0.4639 - val_acc: 0.8514\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2059 - acc: 0.9287 - val_loss: 0.3874 - val_acc: 0.8775\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1951 - acc: 0.9317 - val_loss: 0.3613 - val_acc: 0.9016\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1856 - acc: 0.9378 - val_loss: 0.3995 - val_acc: 0.8962\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1840 - acc: 0.9395 - val_loss: 0.8400 - val_acc: 0.8069\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1688 - acc: 0.9419 - val_loss: 0.3263 - val_acc: 0.9046\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1632 - acc: 0.9412 - val_loss: 0.3485 - val_acc: 0.9084\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1720 - acc: 0.9406 - val_loss: 0.5378 - val_acc: 0.8907\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1777 - acc: 0.9358 - val_loss: 0.4859 - val_acc: 0.8880\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1685 - acc: 0.9445 - val_loss: 0.5723 - val_acc: 0.8843\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1805 - acc: 0.9399 - val_loss: 0.3006 - val_acc: 0.9060\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1626 - acc: 0.9442 - val_loss: 0.4200 - val_acc: 0.8999\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1536 - acc: 0.9455 - val_loss: 0.3939 - val_acc: 0.9046\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1475 - acc: 0.9452 - val_loss: 0.3903 - val_acc: 0.8958\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1397 - acc: 0.9495 - val_loss: 0.3058 - val_acc: 0.9053\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1498 - acc: 0.9463 - val_loss: 0.3560 - val_acc: 0.9172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c969376400>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        25        0                   0   \n",
      "SITTING                  0      374       114        2                   1   \n",
      "STANDING                 0       62       468        2                   0   \n",
      "WALKING                  0        0         0      471                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 417   \n",
      "WALKING_UPSTAIRS         0        0         1        5                   2   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             2  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                           25  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 463  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 920us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3560266619481148, 0.9172039362063115]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 128 hidden layer , 0.5 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 64\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,430\n",
      "Trainable params: 71,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 1.3629 - acc: 0.4023 - val_loss: 1.2220 - val_acc: 0.5005\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 1.0655 - acc: 0.5375 - val_loss: 1.0993 - val_acc: 0.4795\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 1.0112 - acc: 0.5445 - val_loss: 1.3387 - val_acc: 0.5117\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.9601 - acc: 0.5740 - val_loss: 0.8010 - val_acc: 0.6040\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 99s 13ms/step - loss: 0.7705 - acc: 0.6198 - val_loss: 0.9493 - val_acc: 0.5833\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 99s 13ms/step - loss: 0.7869 - acc: 0.6217 - val_loss: 0.7341 - val_acc: 0.6369\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.7029 - acc: 0.6869 - val_loss: 0.7891 - val_acc: 0.6115\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 1.2704 - acc: 0.4800 - val_loss: 1.2444 - val_acc: 0.4937\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.8594 - acc: 0.6300 - val_loss: 0.7524 - val_acc: 0.6362\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.6271 - acc: 0.7114 - val_loss: 0.6853 - val_acc: 0.7068\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.4928 - acc: 0.7765 - val_loss: 0.5443 - val_acc: 0.7635\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 98s 13ms/step - loss: 0.4744 - acc: 0.8040 - val_loss: 0.4959 - val_acc: 0.7900\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.3626 - acc: 0.8630 - val_loss: 0.4288 - val_acc: 0.8470\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 96s 13ms/step - loss: 0.2836 - acc: 0.9023 - val_loss: 0.3743 - val_acc: 0.8761\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.2486 - acc: 0.9172 - val_loss: 0.3145 - val_acc: 0.8975\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1708 - acc: 0.9399 - val_loss: 0.3640 - val_acc: 0.8755\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1595 - acc: 0.9361 - val_loss: 0.3514 - val_acc: 0.8955\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1937 - acc: 0.9287 - val_loss: 0.3683 - val_acc: 0.8897\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1595 - acc: 0.9382 - val_loss: 0.3122 - val_acc: 0.8968\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2371 - acc: 0.9240 - val_loss: 0.2978 - val_acc: 0.9013\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 0.2484 - acc: 0.9131 - val_loss: 0.2934 - val_acc: 0.9043\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1540 - acc: 0.9426 - val_loss: 0.2966 - val_acc: 0.9141\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1481 - acc: 0.9412 - val_loss: 0.3118 - val_acc: 0.9036\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 135s 18ms/step - loss: 0.1600 - acc: 0.9415 - val_loss: 0.3832 - val_acc: 0.8290\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 129s 18ms/step - loss: 0.1637 - acc: 0.9358 - val_loss: 0.2714 - val_acc: 0.9070\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 130s 18ms/step - loss: 0.1748 - acc: 0.9366 - val_loss: 0.2632 - val_acc: 0.9192\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 129s 18ms/step - loss: 0.1739 - acc: 0.9363 - val_loss: 0.2699 - val_acc: 0.9121\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 129s 18ms/step - loss: 0.1280 - acc: 0.9490 - val_loss: 0.3051 - val_acc: 0.9087\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 128s 17ms/step - loss: 0.1325 - acc: 0.9494 - val_loss: 0.3143 - val_acc: 0.9138\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 127s 17ms/step - loss: 0.1388 - acc: 0.9382 - val_loss: 0.3890 - val_acc: 0.9033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c973c32828>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 509        0         0        0                   0   \n",
      "SITTING                  0      341       132        0                   0   \n",
      "STANDING                 0       40       492        0                   0   \n",
      "WALKING                  0        0         0      457                  39   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0       21                   7   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            28  \n",
      "SITTING                           18  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 443  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38895147200638264, 0.9032914828639295]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 64 hidden layer , 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 1.3844 - acc: 0.3992 - val_loss: 1.2437 - val_acc: 0.5334\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.9453 - acc: 0.5687 - val_loss: 0.7735 - val_acc: 0.6532\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.7157 - acc: 0.6827 - val_loss: 0.6914 - val_acc: 0.7245\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.6581 - acc: 0.7206 - val_loss: 0.6682 - val_acc: 0.7346\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.6684 - acc: 0.7592 - val_loss: 0.4976 - val_acc: 0.8229\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.3869 - acc: 0.8719 - val_loss: 0.4056 - val_acc: 0.8473\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.2653 - acc: 0.9143 - val_loss: 0.3255 - val_acc: 0.8897\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.2549 - acc: 0.9168 - val_loss: 0.2987 - val_acc: 0.8853\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.2207 - acc: 0.9260 - val_loss: 0.3630 - val_acc: 0.8877\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1690 - acc: 0.9416 - val_loss: 0.2723 - val_acc: 0.9084\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1749 - acc: 0.9382 - val_loss: 0.3362 - val_acc: 0.8968\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.1691 - acc: 0.9402 - val_loss: 0.3417 - val_acc: 0.8921\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1673 - acc: 0.9396 - val_loss: 0.2993 - val_acc: 0.9057\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1750 - acc: 0.9373 - val_loss: 0.3366 - val_acc: 0.8884\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 33s 4ms/step - loss: 0.1600 - acc: 0.9425 - val_loss: 0.3760 - val_acc: 0.8924\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2679 - acc: 0.9191 - val_loss: 0.2965 - val_acc: 0.9036\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1648 - acc: 0.9429 - val_loss: 0.2840 - val_acc: 0.9074\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1582 - acc: 0.9404 - val_loss: 0.4432 - val_acc: 0.8836\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2095 - acc: 0.9255 - val_loss: 0.5656 - val_acc: 0.7333\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2182 - acc: 0.9176 - val_loss: 0.4422 - val_acc: 0.8955\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1540 - acc: 0.9431 - val_loss: 0.2971 - val_acc: 0.9026\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1955 - acc: 0.9261 - val_loss: 0.4110 - val_acc: 0.9006\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.2389 - acc: 0.9331 - val_loss: 2.7311 - val_acc: 0.5755\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.4790 - acc: 0.8452 - val_loss: 0.3039 - val_acc: 0.8816\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1894 - acc: 0.9374 - val_loss: 0.2664 - val_acc: 0.9036\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1547 - acc: 0.9455 - val_loss: 0.2727 - val_acc: 0.8965\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1426 - acc: 0.9450 - val_loss: 0.2828 - val_acc: 0.9016\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1403 - acc: 0.9476 - val_loss: 0.3015 - val_acc: 0.9002\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1447 - acc: 0.9450 - val_loss: 0.4093 - val_acc: 0.8748\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 32s 4ms/step - loss: 0.1522 - acc: 0.9445 - val_loss: 0.2585 - val_acc: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c973c32cf8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      402        88        0                   0   \n",
      "STANDING                 0      111       419        0                   1   \n",
      "WALKING                  0        0         0      454                  24   \n",
      "WALKING_DOWNSTAIRS       0        0         0        4                 411   \n",
      "WALKING_UPSTAIRS         0        0         0       10                  12   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           1  \n",
      "WALKING                           18  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 449  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 939us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2584735866839715, 0.9066847641669494]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM with 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden_1 = 16\n",
    "n_hidden_2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 128, 16)           1664      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 32)                6272      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 8,134\n",
      "Trainable params: 8,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True,kernel_initializer='he_normal', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='he_normal'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 1.3254 - acc: 0.4917 - val_loss: 1.0015 - val_acc: 0.5891\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8637 - acc: 0.6438 - val_loss: 0.8016 - val_acc: 0.6447\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.7638 - acc: 0.6499 - val_loss: 0.7822 - val_acc: 0.6464\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.7106 - acc: 0.6828 - val_loss: 0.7904 - val_acc: 0.6390\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.6412 - acc: 0.7401 - val_loss: 0.6707 - val_acc: 0.7068\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.5676 - acc: 0.7825 - val_loss: 0.7105 - val_acc: 0.7129\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.5116 - acc: 0.8097 - val_loss: 0.6182 - val_acc: 0.7699\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.4734 - acc: 0.8380 - val_loss: 0.6078 - val_acc: 0.7879\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.3953 - acc: 0.8675 - val_loss: 0.6065 - val_acc: 0.8147\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.3608 - acc: 0.8795 - val_loss: 0.5976 - val_acc: 0.8273\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.3116 - acc: 0.8981 - val_loss: 0.6183 - val_acc: 0.8174\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2796 - acc: 0.9144 - val_loss: 0.6757 - val_acc: 0.8487\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2641 - acc: 0.9149 - val_loss: 0.6181 - val_acc: 0.8568\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2683 - acc: 0.9174 - val_loss: 0.6106 - val_acc: 0.8429\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2838 - acc: 0.9174 - val_loss: 0.4537 - val_acc: 0.8639\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2337 - acc: 0.9233 - val_loss: 0.5148 - val_acc: 0.8649\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2236 - acc: 0.9280 - val_loss: 0.5752 - val_acc: 0.8599\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 77s 11ms/step - loss: 0.2190 - acc: 0.9334 - val_loss: 0.6354 - val_acc: 0.8432\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2152 - acc: 0.9310 - val_loss: 0.4972 - val_acc: 0.8775\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2041 - acc: 0.9336 - val_loss: 0.4954 - val_acc: 0.8775\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1990 - acc: 0.9323 - val_loss: 0.6144 - val_acc: 0.8551\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2060 - acc: 0.9285 - val_loss: 0.4784 - val_acc: 0.8856\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1921 - acc: 0.9376 - val_loss: 0.3911 - val_acc: 0.8928\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2035 - acc: 0.9324 - val_loss: 0.5413 - val_acc: 0.8646\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1901 - acc: 0.9363 - val_loss: 0.4896 - val_acc: 0.8863\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1594 - acc: 0.9445 - val_loss: 0.4502 - val_acc: 0.8951\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1655 - acc: 0.9395 - val_loss: 0.4477 - val_acc: 0.8778\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1698 - acc: 0.9393 - val_loss: 0.3549 - val_acc: 0.8941\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1561 - acc: 0.9416 - val_loss: 0.4630 - val_acc: 0.9013\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1526 - acc: 0.9444 - val_loss: 0.3706 - val_acc: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c97f415668>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      395        69        1                   3   \n",
      "STANDING                 0       95       434        3                   0   \n",
      "WALKING                  0        0         0      471                  20   \n",
      "WALKING_DOWNSTAIRS       0        0         0        4                 416   \n",
      "WALKING_UPSTAIRS         0        0         0       42                  19   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           23  \n",
      "STANDING                           0  \n",
      "WALKING                            5  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 410  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.37058800065051384, 0.9036308109942314]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM with 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,726\n",
      "Trainable params: 30,662\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True,kernel_initializer='he_normal', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='he_normal'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 112s 15ms/step - loss: 1.0839 - acc: 0.5547 - val_loss: 0.7810 - val_acc: 0.7095\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.6937 - acc: 0.7250 - val_loss: 0.8269 - val_acc: 0.7272\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 122s 17ms/step - loss: 0.5083 - acc: 0.8234 - val_loss: 0.4994 - val_acc: 0.8310\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.3190 - acc: 0.9059 - val_loss: 0.5836 - val_acc: 0.8344\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.2739 - acc: 0.9149 - val_loss: 0.4901 - val_acc: 0.8677\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.2265 - acc: 0.9308 - val_loss: 0.5953 - val_acc: 0.8032\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.2171 - acc: 0.9283 - val_loss: 0.4918 - val_acc: 0.8643\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 108s 15ms/step - loss: 0.1956 - acc: 0.9347 - val_loss: 0.4341 - val_acc: 0.8802\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 107s 14ms/step - loss: 0.1767 - acc: 0.9388 - val_loss: 0.4110 - val_acc: 0.8924\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1877 - acc: 0.9363 - val_loss: 0.8660 - val_acc: 0.8110\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 99s 13ms/step - loss: 0.2184 - acc: 0.9204 - val_loss: 0.4763 - val_acc: 0.8778\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.1934 - acc: 0.9346 - val_loss: 0.4630 - val_acc: 0.8867\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.1874 - acc: 0.9366 - val_loss: 0.4349 - val_acc: 0.8856\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1987 - acc: 0.9336 - val_loss: 0.4635 - val_acc: 0.8962\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.1758 - acc: 0.9382 - val_loss: 0.4676 - val_acc: 0.8860\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1711 - acc: 0.9362 - val_loss: 0.3853 - val_acc: 0.9050\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.1465 - acc: 0.9456 - val_loss: 0.4742 - val_acc: 0.8894\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 111s 15ms/step - loss: 0.1400 - acc: 0.9489 - val_loss: 0.4104 - val_acc: 0.9019\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 177s 24ms/step - loss: 0.1445 - acc: 0.9480 - val_loss: 0.4997 - val_acc: 0.8972\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 131s 18ms/step - loss: 0.1423 - acc: 0.9393 - val_loss: 0.4934 - val_acc: 0.8972\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.1682 - acc: 0.9410 - val_loss: 0.4528 - val_acc: 0.8989\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 204s 28ms/step - loss: 0.1517 - acc: 0.9476 - val_loss: 0.4612 - val_acc: 0.8982\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 214s 29ms/step - loss: 0.1391 - acc: 0.9452 - val_loss: 0.4634 - val_acc: 0.9084\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 112s 15ms/step - loss: 0.1348 - acc: 0.9440 - val_loss: 0.7035 - val_acc: 0.8324\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 128s 17ms/step - loss: 0.1404 - acc: 0.9414 - val_loss: 0.4674 - val_acc: 0.8955\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 138s 19ms/step - loss: 0.1257 - acc: 0.9505 - val_loss: 0.4300 - val_acc: 0.9033\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 130s 18ms/step - loss: 0.1323 - acc: 0.9494 - val_loss: 0.4208 - val_acc: 0.8985\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 120s 16ms/step - loss: 0.1410 - acc: 0.9486 - val_loss: 0.5331 - val_acc: 0.8928\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 111s 15ms/step - loss: 0.1437 - acc: 0.9457 - val_loss: 0.4317 - val_acc: 0.8992\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.1311 - acc: 0.9536 - val_loss: 0.4753 - val_acc: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c913c86ef0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  1      410        72        0                   4   \n",
      "STANDING                 0      103       428        1                   0   \n",
      "WALKING                  0        0         0      454                  39   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 412   \n",
      "WALKING_UPSTAIRS         0        0         0        1                  21   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            4  \n",
      "STANDING                           0  \n",
      "WALKING                            3  \n",
      "WALKING_DOWNSTAIRS                 8  \n",
      "WALKING_UPSTAIRS                 449  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.475318681690802, 0.9036308109942314]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM with 0.5 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_35 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,726\n",
      "Trainable params: 30,662\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='glorot_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.9050 - acc: 0.6273 - val_loss: 0.6982 - val_acc: 0.7550\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.4140 - acc: 0.8583 - val_loss: 0.8369 - val_acc: 0.7041\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.3095 - acc: 0.9057 - val_loss: 0.2999 - val_acc: 0.8870\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1961 - acc: 0.9340 - val_loss: 0.3071 - val_acc: 0.8996\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1726 - acc: 0.9387 - val_loss: 0.3658 - val_acc: 0.8789\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1729 - acc: 0.9421 - val_loss: 0.9548 - val_acc: 0.7482\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1844 - acc: 0.9297 - val_loss: 0.2892 - val_acc: 0.8924\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1654 - acc: 0.9378 - val_loss: 0.3075 - val_acc: 0.8982\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1470 - acc: 0.9402 - val_loss: 0.2770 - val_acc: 0.9067\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1585 - acc: 0.9427 - val_loss: 0.3487 - val_acc: 0.8999\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1445 - acc: 0.9406 - val_loss: 0.2768 - val_acc: 0.9162\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1443 - acc: 0.9436 - val_loss: 0.2832 - val_acc: 0.9091\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1516 - acc: 0.9446 - val_loss: 0.4790 - val_acc: 0.8493\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1531 - acc: 0.9460 - val_loss: 0.2331 - val_acc: 0.9175\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1411 - acc: 0.9487 - val_loss: 0.2541 - val_acc: 0.9138\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1343 - acc: 0.9468 - val_loss: 0.2446 - val_acc: 0.9209\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1279 - acc: 0.9486 - val_loss: 0.2724 - val_acc: 0.9158\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1316 - acc: 0.9468 - val_loss: 0.2667 - val_acc: 0.9067\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1335 - acc: 0.9464 - val_loss: 0.2957 - val_acc: 0.9070\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1577 - acc: 0.9400 - val_loss: 0.2553 - val_acc: 0.9175\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1226 - acc: 0.9520 - val_loss: 0.2497 - val_acc: 0.9135\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1259 - acc: 0.9491 - val_loss: 0.2693 - val_acc: 0.9247\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1208 - acc: 0.9508 - val_loss: 0.2619 - val_acc: 0.9128\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1198 - acc: 0.9531 - val_loss: 0.2751 - val_acc: 0.9084\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1174 - acc: 0.9535 - val_loss: 0.2872 - val_acc: 0.9097\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1158 - acc: 0.9510 - val_loss: 0.2903 - val_acc: 0.9179\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1202 - acc: 0.9489 - val_loss: 0.2697 - val_acc: 0.9152\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1091 - acc: 0.9547 - val_loss: 0.2448 - val_acc: 0.9220\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1132 - acc: 0.9543 - val_loss: 0.2586 - val_acc: 0.9111\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1126 - acc: 0.9546 - val_loss: 0.2919 - val_acc: 0.9155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c92b17f128>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 521        0         0        0                   0   \n",
      "SITTING                  3      372       115        0                   0   \n",
      "STANDING                 0       67       465        0                   0   \n",
      "WALKING                  0        0         0      465                  14   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0       11                   5   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            16  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                           17  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 455  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.291916581574723, 0.9155072955548015]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM with 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_45 (LSTM)               (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,726\n",
      "Trainable params: 30,662\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='glorot_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 1.0121 - acc: 0.5724 - val_loss: 0.6597 - val_acc: 0.7363\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.4939 - acc: 0.8211 - val_loss: 0.3863 - val_acc: 0.8768\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.2888 - acc: 0.9087 - val_loss: 0.3332 - val_acc: 0.8870\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.3069 - acc: 0.9038 - val_loss: 0.3077 - val_acc: 0.8918\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2132 - acc: 0.9294 - val_loss: 0.2635 - val_acc: 0.9101\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1857 - acc: 0.9309 - val_loss: 0.2308 - val_acc: 0.9087\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1483 - acc: 0.9436 - val_loss: 0.2189 - val_acc: 0.9141\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1484 - acc: 0.9433 - val_loss: 0.2082 - val_acc: 0.9277\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1617 - acc: 0.9389 - val_loss: 0.2400 - val_acc: 0.9169\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1456 - acc: 0.9429 - val_loss: 0.2271 - val_acc: 0.9179\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1314 - acc: 0.9464 - val_loss: 0.2378 - val_acc: 0.9226\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1278 - acc: 0.9495 - val_loss: 0.2441 - val_acc: 0.9186\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1784 - acc: 0.9359 - val_loss: 0.2129 - val_acc: 0.9213\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 70s 9ms/step - loss: 0.1694 - acc: 0.9353 - val_loss: 0.1856 - val_acc: 0.9267\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1396 - acc: 0.9450 - val_loss: 0.2419 - val_acc: 0.9158\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1431 - acc: 0.9427 - val_loss: 0.3028 - val_acc: 0.8958\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1467 - acc: 0.9453 - val_loss: 0.2347 - val_acc: 0.9199\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1442 - acc: 0.9463 - val_loss: 0.2033 - val_acc: 0.9274\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1611 - acc: 0.9457 - val_loss: 0.2173 - val_acc: 0.9213\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1382 - acc: 0.9476 - val_loss: 0.2262 - val_acc: 0.9226\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1377 - acc: 0.9478 - val_loss: 0.2301 - val_acc: 0.9274\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1382 - acc: 0.9475 - val_loss: 0.2251 - val_acc: 0.9189\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1222 - acc: 0.9520 - val_loss: 0.2562 - val_acc: 0.9182\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.2284 - acc: 0.9154 - val_loss: 0.2478 - val_acc: 0.9070\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1518 - acc: 0.9372 - val_loss: 0.2469 - val_acc: 0.9125\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1310 - acc: 0.9467 - val_loss: 0.2178 - val_acc: 0.9213\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1553 - acc: 0.9400 - val_loss: 0.2138 - val_acc: 0.9155\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1340 - acc: 0.9425 - val_loss: 0.2044 - val_acc: 0.9253\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1353 - acc: 0.9434 - val_loss: 0.2043 - val_acc: 0.9243\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1253 - acc: 0.9465 - val_loss: 0.2090 - val_acc: 0.9264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c943d40cf8>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  1      376       114        0                   0   \n",
      "STANDING                 0       73       459        0                   0   \n",
      "WALKING                  0        0         0      491                   4   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 403   \n",
      "WALKING_UPSTAIRS         0        0         0        3                   4   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                17  \n",
      "WALKING_UPSTAIRS                 464  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20900893709525392, 0.9263657957244655]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM with 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 30,726\n",
      "Trainable params: 30,662\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "model.add(BatchNormalization())\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='glorot_uniform'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.8693 - acc: 0.6500 - val_loss: 0.6769 - val_acc: 0.7424\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.3918 - acc: 0.8682 - val_loss: 0.6694 - val_acc: 0.7927\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2622 - acc: 0.9153 - val_loss: 0.5943 - val_acc: 0.8548\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2173 - acc: 0.9241 - val_loss: 0.3414 - val_acc: 0.9013\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1808 - acc: 0.9369 - val_loss: 0.3243 - val_acc: 0.8958\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1719 - acc: 0.9362 - val_loss: 0.3135 - val_acc: 0.9040\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1607 - acc: 0.9425 - val_loss: 0.3262 - val_acc: 0.9209\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1507 - acc: 0.9437 - val_loss: 0.3650 - val_acc: 0.9033\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1499 - acc: 0.9440 - val_loss: 0.3708 - val_acc: 0.9094\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1509 - acc: 0.9416 - val_loss: 0.4921 - val_acc: 0.8850\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1464 - acc: 0.9448 - val_loss: 0.2680 - val_acc: 0.9152\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1365 - acc: 0.9452 - val_loss: 0.3285 - val_acc: 0.9091\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1420 - acc: 0.9463 - val_loss: 0.3203 - val_acc: 0.9118\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1371 - acc: 0.9465 - val_loss: 0.2782 - val_acc: 0.9230\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1288 - acc: 0.9504 - val_loss: 0.3200 - val_acc: 0.9094\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1316 - acc: 0.9475 - val_loss: 0.3151 - val_acc: 0.9165\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1343 - acc: 0.9475 - val_loss: 0.5192 - val_acc: 0.9087\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1314 - acc: 0.9482 - val_loss: 0.2831 - val_acc: 0.9270\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1289 - acc: 0.9491 - val_loss: 0.3300 - val_acc: 0.9226\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1266 - acc: 0.9518 - val_loss: 0.4283 - val_acc: 0.9074\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1271 - acc: 0.9498 - val_loss: 0.3897 - val_acc: 0.9138\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1239 - acc: 0.9508 - val_loss: 0.4493 - val_acc: 0.9104\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1230 - acc: 0.9474 - val_loss: 0.5510 - val_acc: 0.9165\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1246 - acc: 0.9501 - val_loss: 0.4235 - val_acc: 0.9108\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1278 - acc: 0.9508 - val_loss: 0.5988 - val_acc: 0.9114\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1283 - acc: 0.9509 - val_loss: 0.4650 - val_acc: 0.9111\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1237 - acc: 0.9516 - val_loss: 0.3996 - val_acc: 0.9145\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1220 - acc: 0.9506 - val_loss: 0.4714 - val_acc: 0.9138\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 0.1129 - acc: 0.9508 - val_loss: 0.4587 - val_acc: 0.9128\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1206 - acc: 0.9533 - val_loss: 0.3896 - val_acc: 0.9135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4362e5898>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      398        89        0                   0   \n",
      "STANDING                 0       85       444        3                   0   \n",
      "WALKING                  0        2         0      480                  14   \n",
      "WALKING_DOWNSTAIRS       0        1         0        7                 406   \n",
      "WALKING_UPSTAIRS         0        6         0       26                  12   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            4  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 6  \n",
      "WALKING_UPSTAIRS                 427  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 5s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38958988227966557, 0.9134713267729895]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM + 1 CNN with 0.5 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 128, 16)           448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128, 16)           64        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64, 32)            6272      \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 32,006\n",
      "Trainable params: 31,974\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://blog.goodaudience.com/predicting-physical-activity-based-on-smartphone-sensor-data-using-cnn-lstm-9182dd13b6bc\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16, (3), input_shape=(X_train.shape[1],X_train.shape[2]), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,kernel_initializer='glorot_uniform',return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='glorot_uniform',return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 87s 12ms/step - loss: 0.9210 - acc: 0.5974 - val_loss: 0.7008 - val_acc: 0.6271\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.6637 - acc: 0.6604 - val_loss: 0.6607 - val_acc: 0.6284\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.5996 - acc: 0.7131 - val_loss: 0.6272 - val_acc: 0.6943\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.5023 - acc: 0.7888 - val_loss: 0.4980 - val_acc: 0.8120\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.3637 - acc: 0.8723 - val_loss: 0.3972 - val_acc: 0.8829\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2687 - acc: 0.9074 - val_loss: 0.4035 - val_acc: 0.8748\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.2206 - acc: 0.9240 - val_loss: 0.3845 - val_acc: 0.8792\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1875 - acc: 0.9306 - val_loss: 0.3245 - val_acc: 0.9026\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1819 - acc: 0.9368 - val_loss: 0.2996 - val_acc: 0.9009\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1709 - acc: 0.9376 - val_loss: 0.3142 - val_acc: 0.9074\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1537 - acc: 0.9433 - val_loss: 0.3222 - val_acc: 0.9084\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1564 - acc: 0.9414 - val_loss: 0.6220 - val_acc: 0.8490\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1971 - acc: 0.9354 - val_loss: 0.3705 - val_acc: 0.8853\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1984 - acc: 0.9334 - val_loss: 0.4213 - val_acc: 0.8904\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1797 - acc: 0.9388 - val_loss: 0.3559 - val_acc: 0.8999\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1556 - acc: 0.9419 - val_loss: 0.4140 - val_acc: 0.8901\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1520 - acc: 0.9421 - val_loss: 0.3360 - val_acc: 0.9087\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1488 - acc: 0.9475 - val_loss: 0.3209 - val_acc: 0.9135\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1423 - acc: 0.9484 - val_loss: 0.3796 - val_acc: 0.9063\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1370 - acc: 0.9486 - val_loss: 0.3506 - val_acc: 0.9108\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1362 - acc: 0.9494 - val_loss: 0.3915 - val_acc: 0.9084\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1248 - acc: 0.9504 - val_loss: 0.3538 - val_acc: 0.9128\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.1231 - acc: 0.9489 - val_loss: 0.3942 - val_acc: 0.9091\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1351 - acc: 0.9479 - val_loss: 0.3566 - val_acc: 0.9006\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1300 - acc: 0.9518 - val_loss: 0.3439 - val_acc: 0.9067\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1358 - acc: 0.9480 - val_loss: 0.3204 - val_acc: 0.9169\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1290 - acc: 0.9497 - val_loss: 0.3003 - val_acc: 0.9135\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1280 - acc: 0.9489 - val_loss: 0.2979 - val_acc: 0.9206\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1249 - acc: 0.9504 - val_loss: 0.2965 - val_acc: 0.9192\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.1192 - acc: 0.9494 - val_loss: 0.3366 - val_acc: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203b73c3898>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      414        67        0                   0   \n",
      "STANDING                 0      102       429        0                   0   \n",
      "WALKING                  0        0         0      472                  24   \n",
      "WALKING_DOWNSTAIRS       0        0         0        7                 408   \n",
      "WALKING_UPSTAIRS         0        0         0       26                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            5  \n",
      "STANDING                           1  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 421  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3366131105210424, 0.9097387173396675]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 LSTM + 2 CNN with 0.6 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 128, 128)          3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 32, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 95,430\n",
      "Trainable params: 95,046\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://blog.goodaudience.com/predicting-physical-activity-based-on-smartphone-sensor-data-using-cnn-lstm-9182dd13b6bc\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, (3), input_shape=(X_train.shape[1],X_train.shape[2]), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "model.add(Conv1D(64,(3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,kernel_initializer='glorot_uniform',return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,kernel_initializer='glorot_uniform',return_sequences=False))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.6))\n",
    "\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.5455 - acc: 0.7973 - val_loss: 0.3852 - val_acc: 0.8544\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.2319 - acc: 0.9226 - val_loss: 0.2402 - val_acc: 0.9189\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1730 - acc: 0.9366 - val_loss: 0.2434 - val_acc: 0.9084\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1738 - acc: 0.9365 - val_loss: 0.2888 - val_acc: 0.8975\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1515 - acc: 0.9406 - val_loss: 0.2445 - val_acc: 0.8958\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1608 - acc: 0.9392 - val_loss: 0.3236 - val_acc: 0.9013\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1455 - acc: 0.9433 - val_loss: 0.2627 - val_acc: 0.9148\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1411 - acc: 0.9472 - val_loss: 0.2503 - val_acc: 0.9128\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1269 - acc: 0.9487 - val_loss: 0.3124 - val_acc: 0.9097\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1277 - acc: 0.9493 - val_loss: 0.2129 - val_acc: 0.9182\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1233 - acc: 0.9495 - val_loss: 0.3013 - val_acc: 0.9114\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1273 - acc: 0.9457 - val_loss: 0.2215 - val_acc: 0.9087\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1233 - acc: 0.9498 - val_loss: 0.3028 - val_acc: 0.9155\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1206 - acc: 0.9471 - val_loss: 0.2143 - val_acc: 0.9345\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1329 - acc: 0.9510 - val_loss: 0.1803 - val_acc: 0.9376\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1178 - acc: 0.9516 - val_loss: 0.3415 - val_acc: 0.9135\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1212 - acc: 0.9499 - val_loss: 0.2432 - val_acc: 0.9301\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1209 - acc: 0.9521 - val_loss: 0.2695 - val_acc: 0.9274\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1178 - acc: 0.9544 - val_loss: 0.2510 - val_acc: 0.9196\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1182 - acc: 0.9513 - val_loss: 0.1802 - val_acc: 0.9287\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1252 - acc: 0.9499 - val_loss: 0.2616 - val_acc: 0.9104\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1136 - acc: 0.9536 - val_loss: 0.2371 - val_acc: 0.9114\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1158 - acc: 0.9538 - val_loss: 0.2233 - val_acc: 0.9277\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1078 - acc: 0.9538 - val_loss: 0.1779 - val_acc: 0.9369\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1076 - acc: 0.9539 - val_loss: 0.1867 - val_acc: 0.9247\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1171 - acc: 0.9498 - val_loss: 0.2697 - val_acc: 0.9253\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1063 - acc: 0.9558 - val_loss: 0.2361 - val_acc: 0.9216\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1128 - acc: 0.9532 - val_loss: 0.3596 - val_acc: 0.9023\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1148 - acc: 0.9536 - val_loss: 0.2205 - val_acc: 0.9372\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.1127 - acc: 0.9547 - val_loss: 0.2594 - val_acc: 0.9257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203d7672b00>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  7      401        82        0                   0   \n",
      "STANDING                 0       83       449        0                   0   \n",
      "WALKING                  0        0         0      478                  18   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         2        2         0        1                  23   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 443  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2594191223808506, 0.9256871394638616]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LSTM + 3 CNN with 0.3 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "n_hidden_1 = 16\n",
    "n_hidden_2 = 16\n",
    "n_hidden_3 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_41 (Conv1D)           (None, 128, 128)          3584      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 128, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 64, 64)            24640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 32, 32)            6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32, 32)            128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 16, 16)            3136      \n",
      "_________________________________________________________________\n",
      "lstm_46 (LSTM)               (None, 16, 16)            2112      \n",
      "_________________________________________________________________\n",
      "lstm_47 (LSTM)               (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 6)                 54        \n",
      "=================================================================\n",
      "Total params: 41,398\n",
      "Trainable params: 40,950\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://blog.goodaudience.com/predicting-physical-activity-based-on-smartphone-sensor-data-using-cnn-lstm-9182dd13b6bc\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128, (3), input_shape=(X_train.shape[1],X_train.shape[2]), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64,(3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(32,(3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=(2),padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_1,return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden_2,return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(LSTM(n_hidden_3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"best_model.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n",
    "callbacks_list =[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.9854 - acc: 0.7237 - val_loss: 0.6418 - val_acc: 0.8412\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84119, saving model to best_model.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.4653 - acc: 0.8800 - val_loss: 0.3590 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84119 to 0.89481, saving model to best_model.hdf5\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.3322 - acc: 0.9104 - val_loss: 0.2944 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89481 to 0.91177, saving model to best_model.hdf5\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2769 - acc: 0.9178 - val_loss: 0.2603 - val_acc: 0.9128\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.91177 to 0.91279, saving model to best_model.hdf5\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2639 - acc: 0.9192 - val_loss: 0.2200 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.91279 to 0.91347, saving model to best_model.hdf5\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2424 - acc: 0.9251 - val_loss: 0.2041 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.91347 to 0.91720, saving model to best_model.hdf5\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2326 - acc: 0.9244 - val_loss: 0.2344 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91720 to 0.91958, saving model to best_model.hdf5\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2205 - acc: 0.9259 - val_loss: 0.1680 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.91958 to 0.93078, saving model to best_model.hdf5\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2038 - acc: 0.9282 - val_loss: 0.1801 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.93078 to 0.94197, saving model to best_model.hdf5\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2193 - acc: 0.9229 - val_loss: 0.1976 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.94197\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.1992 - acc: 0.9320 - val_loss: 0.1846 - val_acc: 0.9274\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.94197\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1915 - acc: 0.9323 - val_loss: 0.1920 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94197\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1937 - acc: 0.9298 - val_loss: 0.1628 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94197\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1831 - acc: 0.9338 - val_loss: 0.1629 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94197\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1722 - acc: 0.9384 - val_loss: 0.1686 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94197\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1708 - acc: 0.9325 - val_loss: 0.1667 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94197\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1614 - acc: 0.9392 - val_loss: 0.1577 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94197\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1679 - acc: 0.9412 - val_loss: 0.3189 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94197\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1800 - acc: 0.9338 - val_loss: 0.1612 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94197\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.1597 - acc: 0.9425 - val_loss: 0.1434 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94197\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1526 - acc: 0.9419 - val_loss: 0.1657 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.94197\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1603 - acc: 0.9429 - val_loss: 0.1580 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94197\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.1532 - acc: 0.9397 - val_loss: 0.1715 - val_acc: 0.9321\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94197\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.1622 - acc: 0.9391 - val_loss: 0.2211 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94197\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 0.1584 - acc: 0.9393 - val_loss: 0.1969 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94197\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.1500 - acc: 0.9440 - val_loss: 0.1506 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.94197 to 0.94435, saving model to best_model.hdf5\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 48s 6ms/step - loss: 0.1490 - acc: 0.9419 - val_loss: 0.1900 - val_acc: 0.9328\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94435\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1457 - acc: 0.9467 - val_loss: 0.1842 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94435\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1590 - acc: 0.9434 - val_loss: 0.1760 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94435\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1477 - acc: 0.9461 - val_loss: 0.2265 - val_acc: 0.9342\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23bb47a8240>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,callbacks=callbacks_list,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the weights of best model\n",
    "model.load_weights(\"best_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  6      399        86        0                   0   \n",
      "STANDING                 0       66       466        0                   0   \n",
      "WALKING                  0        0         0      491                   4   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0        1                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 470  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 10s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15064731126539455, 0.9443501866304717]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1.Tried single layer LSTM models with different dropout,activations and optimizer.\n",
    "\n",
    "2.Single layer LSTM model with 0.6 dropout ,sigmoid activation and rmsprop optimizer gives the best score of 0.917\n",
    "\n",
    "3.Tried dual layer LSTM models with different dropout,activations,kernel initializer and optimizer.\n",
    "\n",
    "4.Dual layer LSTM model with 0.6 dropout ,softmax activation and adam optimizer gives the best score of 0.926\n",
    "\n",
    "6.Score's were improved after adding batch normalization layer\n",
    "\n",
    "7.Tried adding CNN Layer to improve the score.\n",
    "\n",
    "8.3 CNN layers with 3 LSTM layers model gave the best score of 0.944\n",
    "\n",
    "9.Compared all the results with pretty library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------+---------+------------------------+------------+-----------+-------------------+\n",
      "|  Model   |              Layers              | Dropout | Kernal Initiaalization | Activation | Optimizer |       Score       |\n",
      "+----------+----------------------------------+---------+------------------------+------------+-----------+-------------------+\n",
      "|   LSTM   |            single-64             |   0.6   |           -            |  sigmoid   |  rmsprop  | 0.917203936206311 |\n",
      "|   LSTM   |            single-128            |   0.5   |           -            |  sigmoid   |    adam   | 0.903291482863929 |\n",
      "|   LSTM   |            single-64             |   0.6   |           -            |  softmax   |    adam   | 0.906684764166949 |\n",
      "|   LSTM   |            Dual-16+32            |   0.6   |       he_normal        |  sigmoid   |    adam   | 0.903630810994231 |\n",
      "|   LSTM   |            Dual-32+64            |   0.6   |       he_normal        |  sigmoid   |    adam   | 0.903630810994231 |\n",
      "|   LSTM   |            Dual-32+64            |   0.5   |     glorot_uniform     |  softmax   |    adam   | 0.915507295554801 |\n",
      "|   LSTM   |            Dual-32+64            |   0.6   |     glorot_uniform     |  softmax   |    adam   | 0.926365795724465 |\n",
      "|   LSTM   |            Dual-32+64            |   0.6   |     glorot_uniform     |  softmax   |  rmsprop  | 0.913471326772989 |\n",
      "| CNN+LSTM |     1 CNN(16)+2 LSTM(32+64)      |   0.5   |     glorot_uniform     |  sigmoid   |    adam   | 0.909738717339667 |\n",
      "| CNN+LSTM |   2 CNN(128+64)+2 LSTM(64+64)    |   0.6   |     glorot_uniform     |  softmax   |    adam   | 0.925687139463861 |\n",
      "| CNN+LSTM | 3 CNN(128+64+32)+3 LSTM(16+16+8) |   0.3   |     glorot_uniform     |  softmax   |    adam   | 0.944350186630471 |\n",
      "+----------+----------------------------------+---------+------------------------+------------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "x = PrettyTable([\"Model\",\"Layers\",\"Dropout\",\"Kernal Initiaalization\",\"Activation\",\"Optimizer\",\"Score\"])\n",
    "\n",
    "x.add_row([\"LSTM\",\"single-64\",\"0.6\",\"-\",\"sigmoid\",\"rmsprop\",\"0.917203936206311\"])\n",
    "x.add_row([\"LSTM\",\"single-128\",\"0.5\",\"-\",\"sigmoid\",\"adam\",\"0.903291482863929\"])\n",
    "x.add_row([\"LSTM\",\"single-64\",\"0.6\",\"-\",\"softmax\",\"adam\",\"0.906684764166949\"])\n",
    "x.add_row([\"LSTM\",\"Dual-16+32\",\"0.6\",\"he_normal\",\"sigmoid\",\"adam\",\"0.903630810994231\"])\n",
    "x.add_row([\"LSTM\",\"Dual-32+64\",\"0.6\",\"he_normal\",\"sigmoid\",\"adam\",\"0.903630810994231\"])\n",
    "x.add_row([\"LSTM\",\"Dual-32+64\",\"0.5\",\"glorot_uniform\",\"softmax\",\"adam\",\"0.915507295554801\"])\n",
    "x.add_row([\"LSTM\",\"Dual-32+64\",\"0.6\",\"glorot_uniform\",\"softmax\",\"adam\",\"0.926365795724465\"])\n",
    "x.add_row([\"LSTM\",\"Dual-32+64\",\"0.6\",\"glorot_uniform\",\"softmax\",\"rmsprop\",\"0.913471326772989\"])\n",
    "x.add_row([\"CNN+LSTM\",\"1 CNN(16)+2 LSTM(32+64)\",\"0.5\",\"glorot_uniform\",\"sigmoid\",\"adam\",\"0.909738717339667\"])\n",
    "x.add_row([\"CNN+LSTM\",\"2 CNN(128+64)+2 LSTM(64+64)\",\"0.6\",\"glorot_uniform\",\"softmax\",\"adam\",\"0.925687139463861\"])\n",
    "x.add_row([\"CNN+LSTM\",\"3 CNN(128+64+32)+3 LSTM(16+16+8)\",\"0.3\",\"glorot_uniform\",\"softmax\",\"adam\",\"0.944350186630471\"])\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
